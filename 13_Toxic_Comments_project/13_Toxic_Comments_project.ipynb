{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "<img align=\"center\" src=\"https://cdn.hswstatic.com/gif/online-harassment-7-orig.jpg\" width=\"200\" />\n",
    "<p style=\"text-align: center;\">\n",
    "    <font size='5' type='bold'>\n",
    "        <b>Определение токсичных комментариев</b>\n",
    "    </font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>\n",
    "# Содержание\n",
    "\n",
    "<a href='#section_1'>1 Содержание</a>\n",
    "\n",
    "<a href='#section_2'>2 Описание проекта</a>\n",
    "\n",
    "<a href='#section_3'>3 Подготовка</a>\n",
    "\n",
    "<a href='#section_4'>4 Обучение</a>\n",
    "\n",
    "<a href='#section_5'>5 Вывод</a>\n",
    "\n",
    "<a href='#section_6'>6 Чек-лист готовности проекта</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>\n",
    "# Описание проекта\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#top'>Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>\n",
    "# Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rnd_state = 260686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде чем извлечь признаки из текста, упростим его через лемматизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  Explanation\\nWhy the edits made under my usern...  \n",
       "1  D'aww! He matches this background colour I'm s...  \n",
       "2  Hey man, I'm really not trying to edit war. It...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lemmatize(text):\n",
    "    wn = nltk.WordNetLemmatizer()\n",
    "    lemm_list = wn.lemmatize(text)\n",
    "    lemm_text = \"\".join(lemm_list)\n",
    " \n",
    "    return lemm_text\n",
    "\n",
    "df['lemm_text'] = df['text'].apply(lambda x: lemmatize(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От лишних символов текст очистят регулярные выражения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "\n",
       "                                           lemm_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "\n",
       "                                          clear_text  \n",
       "0  Explanation Why the edits made under my userna...  \n",
       "1  D aww He matches this background colour I m se...  \n",
       "2  Hey man I m really not trying to edit war It s...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clear_text(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clear_text = \" \".join(clear_text.split())\n",
    "    return clear_text\n",
    "\n",
    "df['clear_text'] = df['lemm_text'].apply(lambda x: clear_text(x))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#top'>Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_4'></a>\n",
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделим наши данные на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=rnd_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию так, чтобы она определяла токсичность комментариев. Подсчитаем величину TF-IDF для текстов. \n",
    "Обученной моделью классификации определим результаты предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "X_train = train['clear_text'].astype('U')\n",
    "y_train = train['toxic']\n",
    "X_test = test['clear_text'].astype('U')\n",
    "y_test = test['toxic']\n",
    "\n",
    "tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = tf_idf.fit_transform(X_train) \n",
    "tf_idf_test = tf_idf.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(tf_idf_train, y_train)\n",
    "y_pred = pd.Series(model.predict(tf_idf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "        \n",
    "y_pred.value_counts().plot(kind='bar', figsize=(8,4), ax=ax, position=0, color='crimson', width=0.2)\n",
    "y_test.value_counts().plot(kind='bar', figsize=(8,4), ax=ax, position=1, color='orange', width=0.2)\n",
    "\n",
    "plt.title('Toxic Comments')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "ax.legend(['test_pred', 'test_true'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом модель работает хорошо, судя по графикам. Однако нам необходима модель со значением метрики качества F1 не меньше 0.75. Проверим значение F1 нашей текущей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7248154173445126"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить результат настраивая гиперпараметр поиском по сетке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 1), score=0.773, total=  20.1s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 1), score=0.773, total=  19.9s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 1), score=0.776, total=  21.1s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 2), score=0.757, total=  41.1s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 2), score=0.749, total=  38.0s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(1, 2), score=0.749, total=  41.5s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(2, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(2, 2), score=0.561, total=  33.1s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(2, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(2, 2), score=0.571, total=  33.6s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(2, 2) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=10, vectorizer__ngram_range=(2, 2), score=0.565, total=  33.4s\n",
      "[CV] model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 1) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  4.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model=LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 1), score=0.772, total=  27.6s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 1), score=0.777, total=  27.8s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 1) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 1), score=0.780, total=  28.0s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 2), score=0.768, total=  45.8s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 2), score=0.765, total=  46.0s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 2) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(1, 2), score=0.765, total=  46.5s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(2, 2) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(2, 2), score=0.589, total=  35.8s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(2, 2) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(2, 2), score=0.601, total=  44.1s\n",
      "[CV] model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(2, 2) \n",
      "[CV]  model=LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=260686, solver='liblinear', tol=0.0001,\n",
      "                   verbose=0, warm_start=False), model__C=50, vectorizer__ngram_range=(2, 2), score=0.592, total=  37.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 10.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 16s, sys: 2min 38s, total: 10min 55s\n",
      "Wall time: 10min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'model': LogisticRegression(C=50, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                     multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                     random_state=260686, solver='liblinear', tol=0.0001,\n",
       "                     verbose=0, warm_start=False),\n",
       "  'model__C': 50,\n",
       "  'vectorizer__ngram_range': (1, 1)},\n",
       " 0.7765048871405252)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 1))),\n",
    "    ('model', LogisticRegression(random_state=rnd_state, solver='liblinear', max_iter=500))\n",
    "    ])\n",
    "\n",
    "params = [\n",
    "        {\n",
    "            'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "            'model': [LogisticRegression(random_state=rnd_state, solver='liblinear')],\n",
    "            'model__C': [10, 50]\n",
    "        }\n",
    "]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=rnd_state)\n",
    "grid = GridSearchCV(pipe, param_grid=params, scoring='f1', cv=cv, verbose=10)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7762198541783512"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = grid.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#top'>Back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section_5'></a>\n",
    "# Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Модель логистической регрессии с оптимизированными параметрами отлично работает и показывает необходимый результат по значению F1-меры - выше 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#top'>Back to top</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
