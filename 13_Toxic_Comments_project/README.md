# [Определение токсичных комментариев](https://github.com/borisenko-ru/practicum_ds_data/blob/main/13_Toxic_Comments_project/13_Toxic_Comments_project.ipynb)

## Описание проекта

Необходимо создать прототип модели для интернет-магазина, который будет искать токсичные комментарии и отправлять их на модерацию.

Для этого необходимо:

- oбучить модель классифицировать комментарии на позитивные и негативные, используя набор данных с разметкой о токсичности правок.
- постройть модель со значением метрики качества `F1` не меньше `0.75`.

## Описание данных

- text — текст комментария
- toxic — целевой признак

## Структура проекта

1. Подготовка
	- Импорт библиотек
	- Чтение файла и изучение данных
	- Анализ данных
2. Обучение
3. Вывод

## Стек библиотек
`pandas` `matplotlib` `sklearn` `nltk` `re`

## Выводы

Проект завершен. Модель логистической регрессии с оптимизированными параметрами работает и показывает необходимый результат по значению F1-меры - выше 0.75.
